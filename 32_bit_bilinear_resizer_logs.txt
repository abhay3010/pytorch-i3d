Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
Get:2 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [423 kB]
Get:3 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1411 kB]
Get:4 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2150 kB]
Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease
Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [452 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2183 kB]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [31.6 kB]
Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2582 kB]
Fetched 9485 kB in 7s (1327 kB/s)
Reading package lists...
From https://github.com/abhay3010/pytorch-i3d
   f96d7cb..2588ebd  master     -> origin/master
Updating f96d7cb..2588ebd
Fast-forward
 pod.yml          |  18 ++++-----
 resizer_job.yml  | 115 +++++++++++++++++++++++++++++--------------------------
 train_resizer.py |   2 +-
 3 files changed, 71 insertions(+), 64 deletions(-)
debug, starting job
torch device cuda:0
declared model
loading params from file /virat-vr/models/pytorch-i3d/v7_bilinear_32_112002400.pt
loading device cuda:0
ignoring device
logits.conv3d.weight
logits.conv3d.bias
model.Conv3d_1a_7x7.conv3d.weight
model.Conv3d_1a_7x7.bn.weight
model.Conv3d_1a_7x7.bn.bias
model.Conv3d_1a_7x7.bn.running_mean
model.Conv3d_1a_7x7.bn.running_var
model.Conv3d_1a_7x7.bn.num_batches_tracked
model.Conv3d_2b_1x1.conv3d.weight
model.Conv3d_2b_1x1.bn.weight
model.Conv3d_2b_1x1.bn.bias
model.Conv3d_2b_1x1.bn.running_mean
model.Conv3d_2b_1x1.bn.running_var
model.Conv3d_2b_1x1.bn.num_batches_tracked
model.Conv3d_2c_3x3.conv3d.weight
model.Conv3d_2c_3x3.bn.weight
model.Conv3d_2c_3x3.bn.bias
model.Conv3d_2c_3x3.bn.running_mean
model.Conv3d_2c_3x3.bn.running_var
model.Conv3d_2c_3x3.bn.num_batches_tracked
model.Mixed_3b.b0.conv3d.weight
model.Mixed_3b.b0.bn.weight
model.Mixed_3b.b0.bn.bias
model.Mixed_3b.b0.bn.running_mean
model.Mixed_3b.b0.bn.running_var
model.Mixed_3b.b0.bn.num_batches_tracked
model.Mixed_3b.b1a.conv3d.weight
model.Mixed_3b.b1a.bn.weight
model.Mixed_3b.b1a.bn.bias
model.Mixed_3b.b1a.bn.running_mean
model.Mixed_3b.b1a.bn.running_var
model.Mixed_3b.b1a.bn.num_batches_tracked
model.Mixed_3b.b1b.conv3d.weight
model.Mixed_3b.b1b.bn.weight
model.Mixed_3b.b1b.bn.bias
model.Mixed_3b.b1b.bn.running_mean
model.Mixed_3b.b1b.bn.running_var
model.Mixed_3b.b1b.bn.num_batches_tracked
model.Mixed_3b.b2a.conv3d.weight
model.Mixed_3b.b2a.bn.weight
model.Mixed_3b.b2a.bn.bias
model.Mixed_3b.b2a.bn.running_mean
model.Mixed_3b.b2a.bn.running_var
model.Mixed_3b.b2a.bn.num_batches_tracked
model.Mixed_3b.b2b.conv3d.weight
model.Mixed_3b.b2b.bn.weight
model.Mixed_3b.b2b.bn.bias
model.Mixed_3b.b2b.bn.running_mean
model.Mixed_3b.b2b.bn.running_var
model.Mixed_3b.b2b.bn.num_batches_tracked
model.Mixed_3b.b3b.conv3d.weight
model.Mixed_3b.b3b.bn.weight
model.Mixed_3b.b3b.bn.bias
model.Mixed_3b.b3b.bn.running_mean
model.Mixed_3b.b3b.bn.running_var
model.Mixed_3b.b3b.bn.num_batches_tracked
model.Mixed_3c.b0.conv3d.weight
model.Mixed_3c.b0.bn.weight
model.Mixed_3c.b0.bn.bias
model.Mixed_3c.b0.bn.running_mean
model.Mixed_3c.b0.bn.running_var
model.Mixed_3c.b0.bn.num_batches_tracked
model.Mixed_3c.b1a.conv3d.weight
model.Mixed_3c.b1a.bn.weight
model.Mixed_3c.b1a.bn.bias
model.Mixed_3c.b1a.bn.running_mean
model.Mixed_3c.b1a.bn.running_var
model.Mixed_3c.b1a.bn.num_batches_tracked
model.Mixed_3c.b1b.conv3d.weight
model.Mixed_3c.b1b.bn.weight
model.Mixed_3c.b1b.bn.bias
model.Mixed_3c.b1b.bn.running_mean
model.Mixed_3c.b1b.bn.running_var
model.Mixed_3c.b1b.bn.num_batches_tracked
model.Mixed_3c.b2a.conv3d.weight
model.Mixed_3c.b2a.bn.weight
model.Mixed_3c.b2a.bn.bias
model.Mixed_3c.b2a.bn.running_mean
model.Mixed_3c.b2a.bn.running_var
model.Mixed_3c.b2a.bn.num_batches_tracked
model.Mixed_3c.b2b.conv3d.weight
model.Mixed_3c.b2b.bn.weight
model.Mixed_3c.b2b.bn.bias
model.Mixed_3c.b2b.bn.running_mean
model.Mixed_3c.b2b.bn.running_var
model.Mixed_3c.b2b.bn.num_batches_tracked
model.Mixed_3c.b3b.conv3d.weight
model.Mixed_3c.b3b.bn.weight
model.Mixed_3c.b3b.bn.bias
model.Mixed_3c.b3b.bn.running_mean
model.Mixed_3c.b3b.bn.running_var
model.Mixed_3c.b3b.bn.num_batches_tracked
model.Mixed_4b.b0.conv3d.weight
model.Mixed_4b.b0.bn.weight
model.Mixed_4b.b0.bn.bias
model.Mixed_4b.b0.bn.running_mean
model.Mixed_4b.b0.bn.running_var
model.Mixed_4b.b0.bn.num_batches_tracked
model.Mixed_4b.b1a.conv3d.weight
model.Mixed_4b.b1a.bn.weight
model.Mixed_4b.b1a.bn.bias
model.Mixed_4b.b1a.bn.running_mean
model.Mixed_4b.b1a.bn.running_var
model.Mixed_4b.b1a.bn.num_batches_tracked
model.Mixed_4b.b1b.conv3d.weight
model.Mixed_4b.b1b.bn.weight
model.Mixed_4b.b1b.bn.bias
model.Mixed_4b.b1b.bn.running_mean
model.Mixed_4b.b1b.bn.running_var
model.Mixed_4b.b1b.bn.num_batches_tracked
model.Mixed_4b.b2a.conv3d.weight
model.Mixed_4b.b2a.bn.weight
model.Mixed_4b.b2a.bn.bias
model.Mixed_4b.b2a.bn.running_mean
model.Mixed_4b.b2a.bn.running_var
model.Mixed_4b.b2a.bn.num_batches_tracked
model.Mixed_4b.b2b.conv3d.weight
model.Mixed_4b.b2b.bn.weight
model.Mixed_4b.b2b.bn.bias
model.Mixed_4b.b2b.bn.running_mean
model.Mixed_4b.b2b.bn.running_var
model.Mixed_4b.b2b.bn.num_batches_tracked
model.Mixed_4b.b3b.conv3d.weight
model.Mixed_4b.b3b.bn.weight
model.Mixed_4b.b3b.bn.bias
model.Mixed_4b.b3b.bn.running_mean
model.Mixed_4b.b3b.bn.running_var
model.Mixed_4b.b3b.bn.num_batches_tracked
model.Mixed_4c.b0.conv3d.weight
model.Mixed_4c.b0.bn.weight
model.Mixed_4c.b0.bn.bias
model.Mixed_4c.b0.bn.running_mean
model.Mixed_4c.b0.bn.running_var
model.Mixed_4c.b0.bn.num_batches_tracked
model.Mixed_4c.b1a.conv3d.weight
model.Mixed_4c.b1a.bn.weight
model.Mixed_4c.b1a.bn.bias
model.Mixed_4c.b1a.bn.running_mean
model.Mixed_4c.b1a.bn.running_var
model.Mixed_4c.b1a.bn.num_batches_tracked
model.Mixed_4c.b1b.conv3d.weight
model.Mixed_4c.b1b.bn.weight
model.Mixed_4c.b1b.bn.bias
model.Mixed_4c.b1b.bn.running_mean
model.Mixed_4c.b1b.bn.running_var
model.Mixed_4c.b1b.bn.num_batches_tracked
model.Mixed_4c.b2a.conv3d.weight
model.Mixed_4c.b2a.bn.weight
model.Mixed_4c.b2a.bn.bias
model.Mixed_4c.b2a.bn.running_mean
model.Mixed_4c.b2a.bn.running_var
model.Mixed_4c.b2a.bn.num_batches_tracked
model.Mixed_4c.b2b.conv3d.weight
model.Mixed_4c.b2b.bn.weight
model.Mixed_4c.b2b.bn.bias
model.Mixed_4c.b2b.bn.running_mean
model.Mixed_4c.b2b.bn.running_var
model.Mixed_4c.b2b.bn.num_batches_tracked
model.Mixed_4c.b3b.conv3d.weight
model.Mixed_4c.b3b.bn.weight
model.Mixed_4c.b3b.bn.bias
model.Mixed_4c.b3b.bn.running_mean
model.Mixed_4c.b3b.bn.running_var
model.Mixed_4c.b3b.bn.num_batches_tracked
model.Mixed_4d.b0.conv3d.weight
model.Mixed_4d.b0.bn.weight
model.Mixed_4d.b0.bn.bias
model.Mixed_4d.b0.bn.running_mean
model.Mixed_4d.b0.bn.running_var
model.Mixed_4d.b0.bn.num_batches_tracked
model.Mixed_4d.b1a.conv3d.weight
model.Mixed_4d.b1a.bn.weight
model.Mixed_4d.b1a.bn.bias
model.Mixed_4d.b1a.bn.running_mean
model.Mixed_4d.b1a.bn.running_var
model.Mixed_4d.b1a.bn.num_batches_tracked
model.Mixed_4d.b1b.conv3d.weight
model.Mixed_4d.b1b.bn.weight
model.Mixed_4d.b1b.bn.bias
model.Mixed_4d.b1b.bn.running_mean
model.Mixed_4d.b1b.bn.running_var
model.Mixed_4d.b1b.bn.num_batches_tracked
model.Mixed_4d.b2a.conv3d.weight
model.Mixed_4d.b2a.bn.weight
model.Mixed_4d.b2a.bn.bias
model.Mixed_4d.b2a.bn.running_mean
model.Mixed_4d.b2a.bn.running_var
model.Mixed_4d.b2a.bn.num_batches_tracked
model.Mixed_4d.b2b.conv3d.weight
model.Mixed_4d.b2b.bn.weight
model.Mixed_4d.b2b.bn.bias
model.Mixed_4d.b2b.bn.running_mean
model.Mixed_4d.b2b.bn.running_var
model.Mixed_4d.b2b.bn.num_batches_tracked
model.Mixed_4d.b3b.conv3d.weight
model.Mixed_4d.b3b.bn.weight
model.Mixed_4d.b3b.bn.bias
model.Mixed_4d.b3b.bn.running_mean
model.Mixed_4d.b3b.bn.running_var
model.Mixed_4d.b3b.bn.num_batches_tracked
model.Mixed_4e.b0.conv3d.weight
model.Mixed_4e.b0.bn.weight
model.Mixed_4e.b0.bn.bias
model.Mixed_4e.b0.bn.running_mean
model.Mixed_4e.b0.bn.running_var
model.Mixed_4e.b0.bn.num_batches_tracked
model.Mixed_4e.b1a.conv3d.weight
model.Mixed_4e.b1a.bn.weight
model.Mixed_4e.b1a.bn.bias
model.Mixed_4e.b1a.bn.running_mean
model.Mixed_4e.b1a.bn.running_var
model.Mixed_4e.b1a.bn.num_batches_tracked
model.Mixed_4e.b1b.conv3d.weight
model.Mixed_4e.b1b.bn.weight
model.Mixed_4e.b1b.bn.bias
model.Mixed_4e.b1b.bn.running_mean
model.Mixed_4e.b1b.bn.running_var
model.Mixed_4e.b1b.bn.num_batches_tracked
model.Mixed_4e.b2a.conv3d.weight
model.Mixed_4e.b2a.bn.weight
model.Mixed_4e.b2a.bn.bias
model.Mixed_4e.b2a.bn.running_mean
model.Mixed_4e.b2a.bn.running_var
model.Mixed_4e.b2a.bn.num_batches_tracked
model.Mixed_4e.b2b.conv3d.weight
model.Mixed_4e.b2b.bn.weight
model.Mixed_4e.b2b.bn.bias
model.Mixed_4e.b2b.bn.running_mean
model.Mixed_4e.b2b.bn.running_var
model.Mixed_4e.b2b.bn.num_batches_tracked
model.Mixed_4e.b3b.conv3d.weight
model.Mixed_4e.b3b.bn.weight
model.Mixed_4e.b3b.bn.bias
model.Mixed_4e.b3b.bn.running_mean
model.Mixed_4e.b3b.bn.running_var
model.Mixed_4e.b3b.bn.num_batches_tracked
model.Mixed_4f.b0.conv3d.weight
model.Mixed_4f.b0.bn.weight
model.Mixed_4f.b0.bn.bias
model.Mixed_4f.b0.bn.running_mean
model.Mixed_4f.b0.bn.running_var
model.Mixed_4f.b0.bn.num_batches_tracked
model.Mixed_4f.b1a.conv3d.weight
model.Mixed_4f.b1a.bn.weight
model.Mixed_4f.b1a.bn.bias
model.Mixed_4f.b1a.bn.running_mean
model.Mixed_4f.b1a.bn.running_var
model.Mixed_4f.b1a.bn.num_batches_tracked
model.Mixed_4f.b1b.conv3d.weight
model.Mixed_4f.b1b.bn.weight
model.Mixed_4f.b1b.bn.bias
model.Mixed_4f.b1b.bn.running_mean
model.Mixed_4f.b1b.bn.running_var
model.Mixed_4f.b1b.bn.num_batches_tracked
model.Mixed_4f.b2a.conv3d.weight
model.Mixed_4f.b2a.bn.weight
model.Mixed_4f.b2a.bn.bias
model.Mixed_4f.b2a.bn.running_mean
model.Mixed_4f.b2a.bn.running_var
model.Mixed_4f.b2a.bn.num_batches_tracked
model.Mixed_4f.b2b.conv3d.weight
model.Mixed_4f.b2b.bn.weight
model.Mixed_4f.b2b.bn.bias
model.Mixed_4f.b2b.bn.running_mean
model.Mixed_4f.b2b.bn.running_var
model.Mixed_4f.b2b.bn.num_batches_tracked
model.Mixed_4f.b3b.conv3d.weight
model.Mixed_4f.b3b.bn.weight
model.Mixed_4f.b3b.bn.bias
model.Mixed_4f.b3b.bn.running_mean
model.Mixed_4f.b3b.bn.running_var
model.Mixed_4f.b3b.bn.num_batches_tracked
model.Mixed_5b.b0.conv3d.weight
model.Mixed_5b.b0.bn.weight
model.Mixed_5b.b0.bn.bias
model.Mixed_5b.b0.bn.running_mean
model.Mixed_5b.b0.bn.running_var
model.Mixed_5b.b0.bn.num_batches_tracked
model.Mixed_5b.b1a.conv3d.weight
model.Mixed_5b.b1a.bn.weight
model.Mixed_5b.b1a.bn.bias
model.Mixed_5b.b1a.bn.running_mean
model.Mixed_5b.b1a.bn.running_var
model.Mixed_5b.b1a.bn.num_batches_tracked
model.Mixed_5b.b1b.conv3d.weight
model.Mixed_5b.b1b.bn.weight
model.Mixed_5b.b1b.bn.bias
model.Mixed_5b.b1b.bn.running_mean
model.Mixed_5b.b1b.bn.running_var
model.Mixed_5b.b1b.bn.num_batches_tracked
model.Mixed_5b.b2a.conv3d.weight
model.Mixed_5b.b2a.bn.weight
model.Mixed_5b.b2a.bn.bias
model.Mixed_5b.b2a.bn.running_mean
model.Mixed_5b.b2a.bn.running_var
model.Mixed_5b.b2a.bn.num_batches_tracked
model.Mixed_5b.b2b.conv3d.weight
model.Mixed_5b.b2b.bn.weight
model.Mixed_5b.b2b.bn.bias
model.Mixed_5b.b2b.bn.running_mean
model.Mixed_5b.b2b.bn.running_var
model.Mixed_5b.b2b.bn.num_batches_tracked
model.Mixed_5b.b3b.conv3d.weight
model.Mixed_5b.b3b.bn.weight
model.Mixed_5b.b3b.bn.bias
model.Mixed_5b.b3b.bn.running_mean
model.Mixed_5b.b3b.bn.running_var
model.Mixed_5b.b3b.bn.num_batches_tracked
model.Mixed_5c.b0.conv3d.weight
model.Mixed_5c.b0.bn.weight
model.Mixed_5c.b0.bn.bias
model.Mixed_5c.b0.bn.running_mean
model.Mixed_5c.b0.bn.running_var
model.Mixed_5c.b0.bn.num_batches_tracked
model.Mixed_5c.b1a.conv3d.weight
model.Mixed_5c.b1a.bn.weight
model.Mixed_5c.b1a.bn.bias
model.Mixed_5c.b1a.bn.running_mean
model.Mixed_5c.b1a.bn.running_var
model.Mixed_5c.b1a.bn.num_batches_tracked
model.Mixed_5c.b1b.conv3d.weight
model.Mixed_5c.b1b.bn.weight
model.Mixed_5c.b1b.bn.bias
model.Mixed_5c.b1b.bn.running_mean
model.Mixed_5c.b1b.bn.running_var
model.Mixed_5c.b1b.bn.num_batches_tracked
model.Mixed_5c.b2a.conv3d.weight
model.Mixed_5c.b2a.bn.weight
model.Mixed_5c.b2a.bn.bias
model.Mixed_5c.b2a.bn.running_mean
model.Mixed_5c.b2a.bn.running_var
model.Mixed_5c.b2a.bn.num_batches_tracked
model.Mixed_5c.b2b.conv3d.weight
model.Mixed_5c.b2b.bn.weight
model.Mixed_5c.b2b.bn.bias
model.Mixed_5c.b2b.bn.running_mean
model.Mixed_5c.b2b.bn.running_var
model.Mixed_5c.b2b.bn.num_batches_tracked
model.Mixed_5c.b3b.conv3d.weight
model.Mixed_5c.b3b.bn.weight
model.Mixed_5c.b3b.bn.bias
model.Mixed_5c.b3b.bn.running_mean
model.Mixed_5c.b3b.bn.running_var
model.Mixed_5c.b3b.bn.num_batches_tracked
label map {'Closing': 0, 'Entering': 1, 'Exiting': 2, 'Interacts': 3, 'Loading': 4, 'Misc': 5, 'Opening': 6, 'Pull': 7, 'Push': 8, 'Riding': 9, 'Talking': 10, 'Transport_HeavyCarry': 11, 'activity_carrying': 12, 'activity_gesturing': 13, 'activity_running': 14, 'activity_standing': 15, 'activity_walking': 16, 'specialized_miscellaneous': 17, 'specialized_talking_phone': 18, 'specialized_texting_phone': 19, 'specialized_using_tool': 20, 'vehicle_moving': 21, 'vehicle_starting': 22, 'vehicle_stopping': 23, 'vehicle_turning_left': 24, 'vehicle_turning_right': 25}
7663 26
resizer network ResizerMainNetworkV2(
  (skip_resizer): ResizerBlock()
  (c1): ConvUnit(
    (conv3d): Conv3d(3, 16, kernel_size=[7, 7, 7], stride=(1, 1, 1), bias=False)
    (act): LeakyReLU(negative_slope=0.2)
  )
  (c2): ConvUnit(
    (conv3d): Conv3d(16, 16, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
    (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
    (act): LeakyReLU(negative_slope=0.2)
  )
  (resizer_first): ResizerBlock()
  (residual_blocks): Sequential(
    (0): ResidualBlock(
      (conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (leaky_relu): LeakyReLU(negative_slope=0.2)
      (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (c3): ConvUnit(
    (conv3d): Conv3d(16, 16, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
    (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
  )
  (c4): ConvUnit(
    (conv3d): Conv3d(16, 3, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
  )
)
i3d InceptionI3d(
  (logits): Unit3D(
    (conv3d): Conv3d(1024, 26, kernel_size=[1, 1, 1], stride=(1, 1, 1))
  )
  (model): Sequential(
    (Conv3d_1a_7x7): Unit3D(
      (conv3d): Conv3d(3, 64, kernel_size=[7, 7, 7], stride=(2, 2, 2), bias=False)
      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (act): ReLU()
    )
    (Conv3d_2b_1x1): Unit3D(
      (conv3d): Conv3d(64, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
      (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (act): ReLU()
    )
    (Conv3d_2c_3x3): Unit3D(
      (conv3d): Conv3d(64, 192, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
      (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (act): ReLU()
    )
    (MaxPool3d_3a_3x3): MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)
    (Mixed_3b): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(192, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(192, 96, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(96, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(192, 16, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(16, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(192, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (Mixed_3c): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(256, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(256, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(128, 192, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(256, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 96, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (MaxPool3d_4a_3x3): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)
    (Mixed_4b): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(480, 192, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(480, 96, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(96, 208, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(208, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(480, 16, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(16, 48, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(480, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (Mixed_4c): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(512, 160, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(512, 112, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(112, 224, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(512, 24, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(24, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(512, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (Mixed_4d): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(128, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(512, 24, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(24, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(512, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (Mixed_4e): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(512, 112, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(512, 144, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(144, 288, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(512, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(512, 64, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (Mixed_4f): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(528, 256, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(528, 160, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(160, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(528, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(528, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (MaxPool3d_5a_2x2): MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)
    (Mixed_5b): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(832, 256, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(832, 160, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(160, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(320, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(832, 32, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(32, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(832, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (Mixed_5c): InceptionModule(
      (b0): Unit3D(
        (conv3d): Conv3d(832, 384, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1a): Unit3D(
        (conv3d): Conv3d(832, 192, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b1b): Unit3D(
        (conv3d): Conv3d(192, 384, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2a): Unit3D(
        (conv3d): Conv3d(832, 48, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b2b): Unit3D(
        (conv3d): Conv3d(48, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
      (b3a): MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)
      (b3b): Unit3D(
        (conv3d): Conv3d(832, 128, kernel_size=[1, 1, 1], stride=(1, 1, 1), bias=False)
        (bn): BatchNorm3d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (act): ReLU()
      )
    )
    (avg_pool): AvgPool3d(kernel_size=[4, 7, 7], stride=(1, 1, 1), padding=0)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
Epoch 0/50
----------
train Loss: 0.0750
train Loss: 0.0387
train Loss: 0.0483
train Loss: 0.0662
train Loss: 0.0401
train Loss: 0.0645
train Loss: 0.0521
train Loss: 0.0514
train Loss: 0.0381
train Loss: 0.0731
train Loss: 0.0538
train Loss: 0.0356
train Loss: 0.0585
train Loss: 0.0486
train Loss: 0.0532
train Loss: 0.0637
train Loss: 0.0455
train Loss: 0.0462
train Loss: 0.0490
train Loss: 0.0602
train Loss: 0.0379
train Loss: 0.0445
train Loss: 0.0558
train Loss: 0.0339
train Loss: 0.0467
train Loss: 0.0379
train Loss: 0.0495
train Loss: 0.0434
train Loss: 0.0468
train Loss: 0.0536
train Loss: 0.0446
train Loss: 0.0399
train Loss: 0.0701
train Loss: 0.0316
train Loss: 0.0263
train Loss: 0.0395
train Loss: 0.0479
train Loss: 0.0350
train Loss: 0.0354
train Loss: 0.0352
train Loss: 0.0303
train Loss: 0.0404
train Loss: 0.0459
train Loss: 0.0467
train Loss: 0.0390
train Loss: 0.0498
train Loss: 0.0425
train Loss: 0.0324
train Loss: 0.0301
train Loss: 0.0485
train Loss: 0.0370
train Loss: 0.0354
train Loss: 0.0444
train Loss: 0.0327
train Loss: 0.0368
train Loss: 0.0370
train Loss: 0.0360
train Loss: 0.0280
train Loss: 0.0426
train Loss: 0.0269
train Loss: 0.0335
train Loss: 0.0295
train Loss: 0.0300
train Loss: 0.0326
train Loss: 0.0314
train Loss: 0.0375
train Loss: 0.0324
train Loss: 0.0429
train Loss: 0.0275
train Loss: 0.0277
train Loss: 0.0365
train Loss: 0.0321
train Loss: 0.0397
train Loss: 0.0392
train Loss: 0.0234
train Loss: 0.0346
train Loss: 0.0396
train Loss: 0.0347
train Loss: 0.0406
train Loss: 0.0365
train Loss: 0.0274
train Loss: 0.0483
val  Loss: 0.0425 
Epoch 1/50
----------
train Loss: 0.0321
train Loss: 0.0300
train Loss: 0.0275
train Loss: 0.0418
train Loss: 0.0294
train Loss: 0.0311
train Loss: 0.0223
train Loss: 0.0344
train Loss: 0.0361
train Loss: 0.0379
train Loss: 0.0508
train Loss: 0.0368
train Loss: 0.0411
train Loss: 0.0313
train Loss: 0.0474
train Loss: 0.0330
train Loss: 0.0373
train Loss: 0.0414
train Loss: 0.0409
train Loss: 0.0291
train Loss: 0.0250
train Loss: 0.0367
train Loss: 0.0205
train Loss: 0.0304
train Loss: 0.0276
train Loss: 0.0442
train Loss: 0.0295
train Loss: 0.0311
train Loss: 0.0216
train Loss: 0.0377
train Loss: 0.0414
train Loss: 0.0315
train Loss: 0.0297
train Loss: 0.0247
train Loss: 0.0252
train Loss: 0.0434
train Loss: 0.0329
train Loss: 0.0360
train Loss: 0.0291
train Loss: 0.0534
train Loss: 0.0397
train Loss: 0.0313
train Loss: 0.0317
train Loss: 0.0348
train Loss: 0.0227
train Loss: 0.0300
train Loss: 0.0295
train Loss: 0.0335
train Loss: 0.0535
train Loss: 0.0299
train Loss: 0.0367
train Loss: 0.0394
train Loss: 0.0194
train Loss: 0.0415
train Loss: 0.0418
train Loss: 0.0345
train Loss: 0.0243
train Loss: 0.0424
train Loss: 0.0355
train Loss: 0.0460
train Loss: 0.0285
train Loss: 0.0326
train Loss: 0.0239
train Loss: 0.0321
train Loss: 0.0324
train Loss: 0.0363
train Loss: 0.0414
train Loss: 0.0272
train Loss: 0.0356
train Loss: 0.0219
train Loss: 0.0349
train Loss: 0.0279
train Loss: 0.0335
train Loss: 0.0206
train Loss: 0.0275
train Loss: 0.0274
train Loss: 0.0311
train Loss: 0.0360
train Loss: 0.0303
train Loss: 0.0359
train Loss: 0.0473
train Loss: 0.0321
val  Loss: 0.0252 
Epoch 2/50
----------
train Loss: 0.0376
train Loss: 0.0403
train Loss: 0.0475
train Loss: 0.0373
train Loss: 0.0335
train Loss: 0.0257
train Loss: 0.0340
train Loss: 0.0366
train Loss: 0.0270
train Loss: 0.0371
train Loss: 0.0355
train Loss: 0.0347
train Loss: 0.0405
train Loss: 0.0322
train Loss: 0.0306
train Loss: 0.0219
train Loss: 0.0284
train Loss: 0.0277
train Loss: 0.0371
train Loss: 0.0345
train Loss: 0.0415
train Loss: 0.0312
train Loss: 0.0304
train Loss: 0.0384
train Loss: 0.0326
train Loss: 0.0345
train Loss: 0.0323
train Loss: 0.0317
train Loss: 0.0412
train Loss: 0.0300
train Loss: 0.0227
train Loss: 0.0352
train Loss: 0.0250
train Loss: 0.0295
train Loss: 0.0269
train Loss: 0.0285
train Loss: 0.0263
train Loss: 0.0330
train Loss: 0.0256
train Loss: 0.0197
train Loss: 0.0209
train Loss: 0.0381
train Loss: 0.0350
train Loss: 0.0249
train Loss: 0.0446
train Loss: 0.0382
train Loss: 0.0294
train Loss: 0.0184
train Loss: 0.0391
train Loss: 0.0388
train Loss: 0.0466
train Loss: 0.0377
train Loss: 0.0345
train Loss: 0.0345
train Loss: 0.0337
train Loss: 0.0201
train Loss: 0.0276
train Loss: 0.0252
train Loss: 0.0200
train Loss: 0.0410
train Loss: 0.0295
train Loss: 0.0364
train Loss: 0.0257
train Loss: 0.0342
train Loss: 0.0215
train Loss: 0.0322
train Loss: 0.0189
train Loss: 0.0348
train Loss: 0.0232
train Loss: 0.0230
train Loss: 0.0430
train Loss: 0.0372
train Loss: 0.0399
train Loss: 0.0247
train Loss: 0.0414
train Loss: 0.0350
train Loss: 0.0245
train Loss: 0.0303
train Loss: 0.0292
train Loss: 0.0391
train Loss: 0.0319
train Loss: 0.0465
val  Loss: 0.0256 
Epoch 3/50
----------
train Loss: 0.0271
train Loss: 0.0169
train Loss: 0.0208
train Loss: 0.0273
train Loss: 0.0304
train Loss: 0.0202
train Loss: 0.0382
train Loss: 0.0281
train Loss: 0.0310
train Loss: 0.0345
train Loss: 0.0239
train Loss: 0.0305
train Loss: 0.0265
train Loss: 0.0336
train Loss: 0.0416
train Loss: 0.0350
train Loss: 0.0197
train Loss: 0.0319
train Loss: 0.0340
train Loss: 0.0355
train Loss: 0.0290
train Loss: 0.0448
train Loss: 0.0375
train Loss: 0.0290
train Loss: 0.0355
train Loss: 0.0286
train Loss: 0.0342
train Loss: 0.0263
train Loss: 0.0344
train Loss: 0.0338
train Loss: 0.0331
train Loss: 0.0204
train Loss: 0.0438
train Loss: 0.0302
train Loss: 0.0327
train Loss: 0.0237
train Loss: 0.0275
train Loss: 0.0416
train Loss: 0.0289
train Loss: 0.0241
train Loss: 0.0180
train Loss: 0.0353
train Loss: 0.0261
train Loss: 0.0229
train Loss: 0.0296
train Loss: 0.0180
train Loss: 0.0285
train Loss: 0.0215
train Loss: 0.0376
train Loss: 0.0306
train Loss: 0.0270
train Loss: 0.0220
train Loss: 0.0253
train Loss: 0.0252
train Loss: 0.0194
train Loss: 0.0374
train Loss: 0.0521
train Loss: 0.0414
train Loss: 0.0451
train Loss: 0.0276
train Loss: 0.0231
train Loss: 0.0266
train Loss: 0.0257
train Loss: 0.0239
train Loss: 0.0389
train Loss: 0.0220
train Loss: 0.0523
train Loss: 0.0267
train Loss: 0.0359
train Loss: 0.0229
train Loss: 0.0335
train Loss: 0.0244
train Loss: 0.0361
train Loss: 0.0272
train Loss: 0.0414
train Loss: 0.0364
train Loss: 0.0208
train Loss: 0.0152
train Loss: 0.0248
train Loss: 0.0212
train Loss: 0.0346
train Loss: 0.0282
val  Loss: 0.0262 
Epoch 4/50
----------
train Loss: 0.0311
train Loss: 0.0235
train Loss: 0.0231
train Loss: 0.0345
train Loss: 0.0354
train Loss: 0.0277
train Loss: 0.0316
train Loss: 0.0451
train Loss: 0.0272
train Loss: 0.0331
train Loss: 0.0368
train Loss: 0.0225
train Loss: 0.0219
train Loss: 0.0224
train Loss: 0.0305
train Loss: 0.0289
train Loss: 0.0394
train Loss: 0.0270
train Loss: 0.0339
train Loss: 0.0329
train Loss: 0.0275
train Loss: 0.0204
train Loss: 0.0342
train Loss: 0.0267
train Loss: 0.0263
train Loss: 0.0260
train Loss: 0.0367
train Loss: 0.0241
train Loss: 0.0205
train Loss: 0.0330
train Loss: 0.0231
train Loss: 0.0268
train Loss: 0.0418
train Loss: 0.0277
train Loss: 0.0314
train Loss: 0.0283
train Loss: 0.0284
train Loss: 0.0229
train Loss: 0.0333
train Loss: 0.0289
train Loss: 0.0278
train Loss: 0.0211
train Loss: 0.0333
train Loss: 0.0215
train Loss: 0.0222
train Loss: 0.0300
train Loss: 0.0204
train Loss: 0.0261
train Loss: 0.0273
train Loss: 0.0301
train Loss: 0.0199
train Loss: 0.0265
train Loss: 0.0314
train Loss: 0.0345
train Loss: 0.0380
train Loss: 0.0307
train Loss: 0.0415
train Loss: 0.0237
train Loss: 0.0341
train Loss: 0.0305
train Loss: 0.0311
train Loss: 0.0282
train Loss: 0.0201
train Loss: 0.0282
train Loss: 0.0353
train Loss: 0.0258
train Loss: 0.0313
train Loss: 0.0242
train Loss: 0.0151
train Loss: 0.0368
train Loss: 0.0329
train Loss: 0.0271
train Loss: 0.0279
train Loss: 0.0375
train Loss: 0.0362
train Loss: 0.0250
train Loss: 0.0201
train Loss: 0.0283
train Loss: 0.0227
train Loss: 0.0324
train Loss: 0.0295
train Loss: 0.0323
val  Loss: 0.0262 
Epoch 5/50
----------
train Loss: 0.0272
train Loss: 0.0309
train Loss: 0.0445
train Loss: 0.0268
train Loss: 0.0439
train Loss: 0.0322
train Loss: 0.0231
train Loss: 0.0385
train Loss: 0.0296
train Loss: 0.0298
train Loss: 0.0257
train Loss: 0.0351
train Loss: 0.0340
train Loss: 0.0269
train Loss: 0.0295
train Loss: 0.0337
train Loss: 0.0407
train Loss: 0.0378
train Loss: 0.0314
train Loss: 0.0483
train Loss: 0.0224
train Loss: 0.0229
train Loss: 0.0250
train Loss: 0.0240
train Loss: 0.0300
train Loss: 0.0222
train Loss: 0.0288
train Loss: 0.0223
train Loss: 0.0231
train Loss: 0.0287
train Loss: 0.0230
train Loss: 0.0277
train Loss: 0.0380
train Loss: 0.0311
train Loss: 0.0252
train Loss: 0.0383
train Loss: 0.0281
train Loss: 0.0382
train Loss: 0.0366
train Loss: 0.0250
train Loss: 0.0182
train Loss: 0.0335
train Loss: 0.0198
train Loss: 0.0183
train Loss: 0.0287
train Loss: 0.0292
train Loss: 0.0304
train Loss: 0.0291
train Loss: 0.0272
train Loss: 0.0246
train Loss: 0.0215
train Loss: 0.0211
train Loss: 0.0235
train Loss: 0.0316
train Loss: 0.0202
train Loss: 0.0176
train Loss: 0.0278
train Loss: 0.0327
train Loss: 0.0294
train Loss: 0.0237
train Loss: 0.0271
train Loss: 0.0275
train Loss: 0.0373
train Loss: 0.0369
train Loss: 0.0380
train Loss: 0.0240
train Loss: 0.0247
train Loss: 0.0175
train Loss: 0.0229
train Loss: 0.0238
train Loss: 0.0248
train Loss: 0.0217
train Loss: 0.0258
train Loss: 0.0313
train Loss: 0.0289
train Loss: 0.0287
train Loss: 0.0226
train Loss: 0.0310
train Loss: 0.0309
train Loss: 0.0157
train Loss: 0.0297
train Loss: 0.0212
val  Loss: 0.0231 
Epoch 6/50
----------
train Loss: 0.0262
train Loss: 0.0232
train Loss: 0.0336
train Loss: 0.0319
train Loss: 0.0280
train Loss: 0.0235
train Loss: 0.0231
train Loss: 0.0324
train Loss: 0.0209
train Loss: 0.0345
train Loss: 0.0303
train Loss: 0.0269
train Loss: 0.0409
train Loss: 0.0256
train Loss: 0.0264
train Loss: 0.0316
train Loss: 0.0286
train Loss: 0.0304
train Loss: 0.0229
train Loss: 0.0371
train Loss: 0.0395
train Loss: 0.0227
train Loss: 0.0199
train Loss: 0.0219
train Loss: 0.0330
train Loss: 0.0335
train Loss: 0.0193
train Loss: 0.0288
train Loss: 0.0327
train Loss: 0.0547
train Loss: 0.0394
train Loss: 0.0256
train Loss: 0.0404
train Loss: 0.0375
train Loss: 0.0216
train Loss: 0.0389
train Loss: 0.0242
train Loss: 0.0267
train Loss: 0.0301
train Loss: 0.0235
train Loss: 0.0176
train Loss: 0.0253
train Loss: 0.0294
train Loss: 0.0259
train Loss: 0.0214
train Loss: 0.0316
train Loss: 0.0301
train Loss: 0.0244
train Loss: 0.0401
train Loss: 0.0261
train Loss: 0.0346
train Loss: 0.0209
train Loss: 0.0295
train Loss: 0.0277
train Loss: 0.0270
train Loss: 0.0267
train Loss: 0.0308
train Loss: 0.0279
train Loss: 0.0426
train Loss: 0.0239
train Loss: 0.0360
train Loss: 0.0136
train Loss: 0.0267
train Loss: 0.0324
train Loss: 0.0369
train Loss: 0.0241
train Loss: 0.0384
train Loss: 0.0211
train Loss: 0.0278
train Loss: 0.0175
train Loss: 0.0329
train Loss: 0.0442
train Loss: 0.0353
train Loss: 0.0345
train Loss: 0.0167
train Loss: 0.0149
train Loss: 0.0107
train Loss: 0.0350
train Loss: 0.0269
train Loss: 0.0164
train Loss: 0.0228
train Loss: 0.0271
val  Loss: 0.0210 
Epoch 7/50
----------
train Loss: 0.0190
train Loss: 0.0119
train Loss: 0.0216
train Loss: 0.0294
train Loss: 0.0195
train Loss: 0.0371
train Loss: 0.0261
train Loss: 0.0467
train Loss: 0.0305
train Loss: 0.0250
train Loss: 0.0309
train Loss: 0.0300
train Loss: 0.0310
train Loss: 0.0215
train Loss: 0.0279
train Loss: 0.0233
train Loss: 0.0265
train Loss: 0.0281
train Loss: 0.0389
train Loss: 0.0228
train Loss: 0.0329
train Loss: 0.0249
train Loss: 0.0218
train Loss: 0.0208
train Loss: 0.0259
train Loss: 0.0280
train Loss: 0.0223
train Loss: 0.0304
train Loss: 0.0202
train Loss: 0.0302
train Loss: 0.0213
train Loss: 0.0253
train Loss: 0.0210
train Loss: 0.0359
train Loss: 0.0313
train Loss: 0.0174
train Loss: 0.0283
train Loss: 0.0273
train Loss: 0.0306
train Loss: 0.0244
train Loss: 0.0250
train Loss: 0.0358
train Loss: 0.0204
train Loss: 0.0233
train Loss: 0.0171
train Loss: 0.0200
train Loss: 0.0259
train Loss: 0.0217
train Loss: 0.0214
train Loss: 0.0296
train Loss: 0.0259
train Loss: 0.0377
train Loss: 0.0357
train Loss: 0.0340
train Loss: 0.0308
train Loss: 0.0338
train Loss: 0.0218
train Loss: 0.0265
train Loss: 0.0275
train Loss: 0.0286
train Loss: 0.0273
train Loss: 0.0194
train Loss: 0.0342
train Loss: 0.0217
train Loss: 0.0246
train Loss: 0.0211
train Loss: 0.0289
train Loss: 0.0288
train Loss: 0.0392
train Loss: 0.0439
train Loss: 0.0309
train Loss: 0.0293
train Loss: 0.0249
train Loss: 0.0206
train Loss: 0.0290
train Loss: 0.0282
train Loss: 0.0243
train Loss: 0.0315
train Loss: 0.0279
train Loss: 0.0257
train Loss: 0.0286
train Loss: 0.0241
val  Loss: 0.0233 
Epoch 8/50
----------
train Loss: 0.0330
train Loss: 0.0278
train Loss: 0.0267
train Loss: 0.0319
train Loss: 0.0242
train Loss: 0.0240
train Loss: 0.0254
train Loss: 0.0206
train Loss: 0.0268
train Loss: 0.0219
train Loss: 0.0235
train Loss: 0.0193
train Loss: 0.0246
train Loss: 0.0246
train Loss: 0.0287
train Loss: 0.0235
train Loss: 0.0199
train Loss: 0.0385
train Loss: 0.0231
train Loss: 0.0255
train Loss: 0.0219
train Loss: 0.0508
train Loss: 0.0242
train Loss: 0.0378
train Loss: 0.0272
train Loss: 0.0169
train Loss: 0.0234
train Loss: 0.0331
train Loss: 0.0161
train Loss: 0.0342
train Loss: 0.0231
train Loss: 0.0276
train Loss: 0.0247
train Loss: 0.0305
train Loss: 0.0250
train Loss: 0.0211
train Loss: 0.0223
train Loss: 0.0375
train Loss: 0.0275
train Loss: 0.0260
train Loss: 0.0232
train Loss: 0.0384
train Loss: 0.0229
train Loss: 0.0268
train Loss: 0.0394
train Loss: 0.0418
train Loss: 0.0255
train Loss: 0.0250
train Loss: 0.0265
train Loss: 0.0412
train Loss: 0.0313
train Loss: 0.0301
train Loss: 0.0295
train Loss: 0.0190
train Loss: 0.0260
train Loss: 0.0162
train Loss: 0.0313
train Loss: 0.0275
train Loss: 0.0268
train Loss: 0.0233
train Loss: 0.0245
train Loss: 0.0176
train Loss: 0.0350
train Loss: 0.0298
train Loss: 0.0213
train Loss: 0.0361
train Loss: 0.0198
train Loss: 0.0321
train Loss: 0.0301
train Loss: 0.0232
train Loss: 0.0364
train Loss: 0.0330
train Loss: 0.0278
train Loss: 0.0241
train Loss: 0.0235
train Loss: 0.0318
train Loss: 0.0332
train Loss: 0.0197
train Loss: 0.0340
train Loss: 0.0317
train Loss: 0.0264
train Loss: 0.0197
val  Loss: 0.0244 
Epoch 9/50
----------
train Loss: 0.0287
train Loss: 0.0196
train Loss: 0.0253
train Loss: 0.0247
train Loss: 0.0206
train Loss: 0.0204
train Loss: 0.0293
train Loss: 0.0194
train Loss: 0.0189
train Loss: 0.0180
train Loss: 0.0313
train Loss: 0.0233
train Loss: 0.0226
train Loss: 0.0274
train Loss: 0.0280
train Loss: 0.0280
train Loss: 0.0247
train Loss: 0.0370
train Loss: 0.0195
train Loss: 0.0187
train Loss: 0.0316
train Loss: 0.0209
train Loss: 0.0410
train Loss: 0.0220
train Loss: 0.0235
train Loss: 0.0250
train Loss: 0.0342
train Loss: 0.0189
train Loss: 0.0208
train Loss: 0.0266
train Loss: 0.0399
train Loss: 0.0335
train Loss: 0.0295
train Loss: 0.0244
train Loss: 0.0210
train Loss: 0.0194
train Loss: 0.0185
train Loss: 0.0241
train Loss: 0.0193
train Loss: 0.0228
train Loss: 0.0194
train Loss: 0.0234
train Loss: 0.0261
train Loss: 0.0315
train Loss: 0.0275
train Loss: 0.0291
train Loss: 0.0391
train Loss: 0.0246
train Loss: 0.0262
train Loss: 0.0292
train Loss: 0.0301
train Loss: 0.0203
train Loss: 0.0229
train Loss: 0.0290
train Loss: 0.0319
train Loss: 0.0266
train Loss: 0.0258
train Loss: 0.0163
train Loss: 0.0387
train Loss: 0.0151
train Loss: 0.0302
train Loss: 0.0327
train Loss: 0.0337
train Loss: 0.0207
train Loss: 0.0294
train Loss: 0.0341
train Loss: 0.0391
train Loss: 0.0237
train Loss: 0.0444
train Loss: 0.0227
train Loss: 0.0399
train Loss: 0.0273
train Loss: 0.0226
train Loss: 0.0317
train Loss: 0.0258
train Loss: 0.0246
train Loss: 0.0263
train Loss: 0.0209
train Loss: 0.0281
train Loss: 0.0340
train Loss: 0.0264
train Loss: 0.0332
val  Loss: 0.0232 
Epoch 10/50
----------
