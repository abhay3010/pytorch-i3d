Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease
Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
Get:4 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1410 kB]
Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
Get:6 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2119 kB]
Get:7 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [399 kB]
Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [429 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2181 kB]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2550 kB]
Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [31.6 kB]
Fetched 9372 kB in 2s (4225 kB/s)
Reading package lists...
From https://github.com/abhay3010/pytorch-i3d
   bedcd07..228e32e  master     -> origin/master
Updating bedcd07..228e32e
Fast-forward
 train_resnet.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
Downloading: "https://download.pytorch.org/models/resnet18-5c106cde.pth" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth
719810 26
488264 26
  0%|          | 0.00/44.7M [00:00<?, ?B/s]  1%|          | 280k/44.7M [00:00<00:16, 2.86MB/s]  7%|▋         | 2.95M/44.7M [00:00<00:11, 3.92MB/s] 47%|████▋     | 21.0M/44.7M [00:00<00:04, 5.55MB/s] 96%|█████████▌| 42.8M/44.7M [00:00<00:00, 7.85MB/s]100%|██████████| 44.7M/44.7M [00:00<00:00, 115MB/s] 
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 fc.weight
	 fc.bias
Epoch 0/25
step  100 0.07014262795448303
step  200 0.05253924946300685
step  300 0.044383775057892004
step  400 0.03925357874017209
step  500 0.03571615062095225
step  600 0.032926539857871834
step  700 0.03059927889278957
step  800 0.02866055303369649
step  900 0.027036415591008132
step  1000 0.025706035044975577
step  1100 0.02455900656398047
step  1200 0.02352673521148972
step  1300 0.022594430325911023
step  1400 0.021770406523386816
step  1500 0.020997603038636348
step  1600 0.020308904530247675
step  1700 0.01968286893768784
step  1800 0.019104637895296844
step  1900 0.0185603124819892
step  2000 0.018057804444804787
step  2100 0.017601813988627067
step  2200 0.017191579650071533
step  2300 0.016805763507828763
step  2400 0.016434661486903982
step  2500 0.016081764012854546
step  2600 0.015759378706481163
step  2700 0.015451914782860074
step  2800 0.015160288963566667
step  100 0.16584377959370614
step  200 0.16538127027451993
step  300 0.16553214187423387
step  400 0.1650497872196138
step  500 0.16514339618384838
step  600 0.16588813316076995
step  700 0.16635823246623788
step  800 0.1664393328782171
step  900 0.1662286291933722
step  1000 0.16628113795071842
step  1100 0.16630051407624374
step  1200 0.16632585014527043
step  1300 0.1662580095976591
step  1400 0.16630536356674774
step  1500 0.16620483740170797
step  1600 0.16609669998288154
step  1700 0.16598864707876654
step  1800 0.1659637387179666
step  1900 0.16593427896499635
val Loss: 0.1659 
Epoch 1/25
step  100 0.006743417987599969
step  200 0.006467191175324842
step  300 0.006545866397985567
step  400 0.006555216033593752
step  500 0.0066615293147042395
step  600 0.006666363773401827
step  700 0.006623308489963944
step  800 0.00657585869950708
step  900 0.006511140686408099
step  1000 0.006480884504737333
step  1100 0.006395016410176388
step  1200 0.006403559946338646
step  1300 0.006381520193356734
step  1400 0.006338864702099402
step  1500 0.006339211887524773
step  1600 0.006316502499830676
step  1700 0.0062774707996012535
step  1800 0.00624592254559199
step  1900 0.006209668208550858
step  2000 0.006174762754002586
step  2100 0.0061360242129081775
step  2200 0.006113740371074527
step  2300 0.006087842855055857
step  2400 0.006065022032610917
step  2500 0.006044124557822943
step  2600 0.006025648212346893
step  2700 0.006001998513195388
step  2800 0.005972733617860025
step  100 0.1982963727414608
step  200 0.19943722993135451
step  300 0.20039035474260647
step  400 0.20061571385711433
step  500 0.20163986751437188
step  600 0.2019292181233565
step  700 0.20187785103917122
step  800 0.20202591413632034
step  900 0.2015801643828551
step  1000 0.20156396520137787
step  1100 0.20138692247596654
step  1200 0.20149636918057998
step  1300 0.2014208230834741
step  1400 0.2013146250801427
step  1500 0.20120329084992408
step  1600 0.20121272955089808
step  1700 0.20125100976404023
step  1800 0.20107932834989495
step  1900 0.2010270035659012
val Loss: 0.2010 
Epoch 2/25
step  100 0.005116954275872558
step  200 0.004965664519695565
step  300 0.004919053399547313
step  400 0.004934725468920078
step  500 0.005035253105917945
step  600 0.004982016964543921
step  700 0.004979274752050904
step  800 0.004920520132582169
step  900 0.004927488385647949
step  1000 0.0049762773599941286
step  1100 0.004999308135910806
step  1200 0.004996586327518647
step  1300 0.004992735057961769
step  1400 0.004971835696155072
step  1500 0.0049388384274983155
step  1600 0.004909164306372987
step  1700 0.0048920006787075716
step  1800 0.004862682632713889
step  1900 0.004834675892121404
step  2000 0.0048289551606285385
step  2100 0.004842389662406363
step  2200 0.0048227499280950395
step  2300 0.004816115834476912
step  2400 0.004814447341486811
step  2500 0.004805355802876875
step  2600 0.0047994635440409186
step  2700 0.004792977749430402
step  2800 0.004779510279393955
step  100 0.22736530840396882
step  200 0.2276531307399273
step  300 0.22490838915109634
step  400 0.22569347489625216
step  500 0.226093845307827
step  600 0.2263194346924623
step  700 0.22602813548275402
step  800 0.22577208172529936
step  900 0.2259740253786246
step  1000 0.2259431409984827
step  1100 0.2259265936775641
step  1200 0.22587173453221718
step  1300 0.22540887638926507
step  1400 0.22517216901694026
step  1500 0.22502686327695848
step  1600 0.2249028730671853
step  1700 0.2252945765239351
step  1800 0.22545608955125013
step  1900 0.22533643691947586
val Loss: 0.2253 
Epoch 3/25
step  100 0.004116612663492561
step  200 0.004257797378813848
step  300 0.004403563375429561
step  400 0.004353691216092557
step  500 0.00436212767707184
step  600 0.004305719891369033
step  700 0.004302573437702709
step  800 0.004282285882072756
step  900 0.004253433640891065
step  1000 0.004268507992266677
step  1100 0.004280217866497961
step  1200 0.0042765016947911745
step  1300 0.004281035255407914
step  1400 0.004307378410345076
step  1500 0.004309000712897007
step  1600 0.004299179739682586
step  1700 0.004274980728788411
step  1800 0.0042433637768004295
step  1900 0.004255931277600068
step  2000 0.004240814969642088
step  2100 0.004230572746157468
step  2200 0.004204409163424068
step  2300 0.004192218531641866
step  2400 0.004178861782711465
step  2500 0.004172583001106977
step  2600 0.004170922127758296
step  2700 0.004160638784782754
step  2800 0.00416161539802228
step  100 0.23464268580079078
step  200 0.23348964355885982
step  300 0.23367746591567992
step  400 0.233772577829659
step  500 0.23396506962180139
step  600 0.2339475256204605
step  700 0.23386420564992086
step  800 0.23368809463456272
step  900 0.23369261423746746
step  1000 0.23314504213631154
step  1100 0.23306163848801092
step  1200 0.2334494090328614
step  1300 0.23349009608993163
step  1400 0.2335156576548304
step  1500 0.23368177663286527
step  1600 0.23354131944477557
step  1700 0.23354821681976318
step  1800 0.2335047182854679
step  1900 0.23322621553352005
val Loss: 0.2333 
Epoch 4/25
step  100 0.003934469791129231
step  200 0.0038573657133383677
step  300 0.003793201355341201
step  400 0.0038143376840162092
step  500 0.003808145746588707
step  600 0.0038226379409510023
step  700 0.003830770021470796
step  800 0.0038015067813103086
step  900 0.0038293029664136055
step  1000 0.0038250265032984316
step  1100 0.0038131810271773824
step  1200 0.00379632749420125
step  1300 0.0038166365454582354
step  1400 0.003822249711042137
step  1500 0.003801705114232997
step  1600 0.0037976039166824193
step  1700 0.003795464142150355
step  1800 0.003793255498910892
step  1900 0.003786948787042332
step  2000 0.0037658750325499568
step  2100 0.0037460636606140595
step  2200 0.0037428284942077217
step  2300 0.003740870011489555
step  2400 0.003724984546546087
step  2500 0.0037188319712644444
step  2600 0.003733776144553513
step  2700 0.0037575646076584233
step  2800 0.0037505627681925294
step  100 0.2459538309276104
step  200 0.24436094239354134
step  300 0.24517773707707724
step  400 0.24554406601935624
step  500 0.2443253346979618
step  600 0.244600079630812
step  700 0.24456363924912045
step  800 0.245170737169683
step  900 0.24519025958246654
step  1000 0.24554175125062466
step  1100 0.24604859474030408
step  1200 0.24618723091979822
step  1300 0.24620259472957023
step  1400 0.2460049358010292
step  1500 0.24575632707277933
step  1600 0.24588914994150401
step  1700 0.24598524382009226
step  1800 0.24603123259213236
step  1900 0.2458050788468436
val Loss: 0.2458 
Epoch 5/25
step  100 0.0035166760301217435
step  200 0.003672076695947908
step  300 0.0036099863009682546
step  400 0.003537289540108759
step  500 0.0035348765123635532
step  600 0.0035085140543136125
step  700 0.003470612426754087
step  800 0.003488295213028323
step  900 0.0034834198080675883
step  1000 0.0035058844580780715
step  1100 0.0035311606186653743
step  1200 0.0035168839857215063
step  1300 0.0035075947822322353
step  1400 0.003502704897296748
step  1500 0.0034995241215995824
step  1600 0.0035165681724538445
step  1700 0.003502584285931388
step  1800 0.003493708375964262
step  1900 0.003498732763262907
step  2000 0.0034829732311482077
step  2100 0.003473869519657455
step  2200 0.0034585835933632386
step  2300 0.0034649546610687493
step  2400 0.0034665260197410436
step  2500 0.0034545343690318988
step  2600 0.0034615105256671085
step  2700 0.0034613972374548515
step  2800 0.003463032106020754
step  100 0.2502004657685757
step  200 0.24861720100045204
step  300 0.24914113700389862
step  400 0.2484278665855527
step  500 0.249887168854475
step  600 0.24982873395085334
step  700 0.2504448626083987
step  800 0.2507128854468465
step  900 0.25078674385945005
step  1000 0.251354013517499
step  1100 0.25157349304719406
step  1200 0.2515658878659209
step  1300 0.251411727804404
step  1400 0.2511385431353535
step  1500 0.25129268707831703
step  1600 0.25129833215847613
step  1700 0.2513259358265821
step  1800 0.25143256364597216
step  1900 0.2513305333099867
val Loss: 0.2513 
Epoch 6/25
step  100 0.0034174471895676104
step  200 0.0034064278489677234
step  300 0.003285553048675259
step  400 0.0032340070349164305
step  500 0.003287923243129626
step  600 0.0032849797228118403
step  700 0.003275338545541412
step  800 0.003258957446232671
step  900 0.003246358819823298
step  1000 0.0032158701652660964
step  1100 0.0032350131281947887
step  1200 0.0032415968352385487
step  1300 0.0032518384029838043
step  1400 0.0032607830828055738
step  1500 0.0032694517668957514
step  1600 0.0032729897337412696
step  1700 0.003265650992089992
step  1800 0.0032543424275677858
step  1900 0.003252218784458053
step  2000 0.003248254794627428
step  2100 0.00324128197910752
step  2200 0.0032422736563338813
step  2300 0.0032331714018389744
step  2400 0.003233991634139481
step  2500 0.0032337072742171587
step  2600 0.0032299736923036668
step  2700 0.003229350664747741
step  2800 0.003227028743713163
step  100 0.262849714756012
step  200 0.2629353900998831
step  300 0.2631633374094963
step  400 0.2629462993144989
step  500 0.2626933584213257
step  600 0.2629938857009014
step  700 0.2629177140550954
step  800 0.26342563025653365
step  900 0.26359850999381806
step  1000 0.26330333383381366
step  1100 0.26343005735765807
step  1200 0.26370519286642474
step  1300 0.2635575368427313
step  1400 0.2636328776393618
step  1500 0.26344186467925707
step  1600 0.26338762551546097
step  1700 0.2634400701259865
step  1800 0.26318502293692697
step  1900 0.2632269489529886
val Loss: 0.2633 
Epoch 7/25
step  100 0.0028102774423314257
step  200 0.002830477844981942
step  300 0.0028462456840012843
step  400 0.0028813316333980766
step  500 0.0028882309774635358
step  600 0.002894527654570993
step  700 0.002940730990625785
step  800 0.002960968370825867
step  900 0.0029853273811103363
step  1000 0.0030009636975009924
step  1100 0.0030491273177639497
step  1200 0.0030484647833024306
step  1300 0.0030346659547649322
step  1400 0.003018292314622418
step  1500 0.0030126259732836235
step  1600 0.0030145044487289853
step  1700 0.003014717915040605
step  1800 0.0030024027751965657
step  1900 0.00301396819634216
step  2000 0.0029997827881597912
step  2100 0.0030099146391287268
step  2200 0.0030028663480400363
step  2300 0.0029947423557599036
step  2400 0.003006815661137807
step  2500 0.0030167558191576973
step  2600 0.0030172458694701513
step  2700 0.0030143935525039625
step  2800 0.0030158195330919364
step  100 0.27658506989479065
step  200 0.27829751014709475
step  300 0.2777192433178425
step  400 0.2783302717655897
step  500 0.2789260895252228
step  600 0.27968509785830975
step  700 0.28013761978064267
step  800 0.27996000107377766
step  900 0.27975114050838684
step  1000 0.2795365781933069
step  1100 0.27932405017993667
step  1200 0.27916955885787803
step  1300 0.2790611115212624
step  1400 0.2790747787484101
step  1500 0.2792196392218272
step  1600 0.27895669064484535
step  1700 0.2788212667756221
step  1800 0.2787599282132255
step  1900 0.27876050904393196
val Loss: 0.2787 
Epoch 8/25
step  100 0.0025773603591369466
step  200 0.0027612098914687523
step  300 0.0027619419153779743
step  400 0.0028550885285949334
step  500 0.0028715680688619614
step  600 0.0028701444680336863
step  700 0.002915417561473857
step  800 0.0028842580795753747
step  900 0.0028767808246064103
step  1000 0.0028734949947101995
step  1100 0.0028849306800508533
step  1200 0.002892054408681967
step  1300 0.0028783033382989323
step  1400 0.0028846164069338035
step  1500 0.0028870300691730033
step  1600 0.0028855279606432305
step  1700 0.0028849210276829956
step  1800 0.0028879586878530162
step  1900 0.002885344916292907
step  2000 0.0028883101382525637
step  2100 0.0028901077994045667
step  2200 0.002896269428549038
step  2300 0.002908488668719023
step  2400 0.0029036786977909893
step  2500 0.002900835131597705
step  2600 0.002894842820712186
step  2700 0.0028974361914960254
step  2800 0.0028928074868287824
step  100 0.3080020126700401
step  200 0.3047937782108784
step  300 0.3029015763600667
step  400 0.3030023144185543
step  500 0.30219787046313284
step  600 0.30330634117126465
step  700 0.3036546556864466
step  800 0.30387464648112655
step  900 0.30302296289139324
step  1000 0.3032704887241125
step  1100 0.30301360585472803
step  1200 0.30304085443417234
step  1300 0.30307446165726737
step  1400 0.3027013975062541
step  1500 0.3028008819917838
step  1600 0.30303371844813226
step  1700 0.3028136136689607
step  1800 0.30260593632029165
step  1900 0.30287639017167844
val Loss: 0.3029 
Epoch 9/25
step  100 0.0027182594721671194
step  200 0.002691855146549642
step  300 0.0026553961729708438
step  400 0.0026759576419135554
step  500 0.002690986763453111
step  600 0.0026587811081359783
step  700 0.002666509515256621
step  800 0.0026626715454040094
step  900 0.0026733981238471136
step  1000 0.002695021523628384
step  1100 0.002700772319116037
step  1200 0.00272188241321904
step  1300 0.002743121390678705
step  1400 0.002740698046815981
step  1500 0.0027367551701220996
step  1600 0.0027418258302350294
step  1700 0.002752494818996638
step  1800 0.0027532610352176967
step  1900 0.0027658137665007654
step  2000 0.0027615553152863866
step  2100 0.002757427743053995
step  2200 0.0027543278040618384
step  2300 0.002752875916168863
step  2400 0.0027586712502428177
step  2500 0.002759511657198891
step  2600 0.002751928070031751
step  2700 0.002749227507177878
step  2800 0.0027476370577850114
step  100 0.3081411054730415
step  200 0.30762173913419244
step  300 0.3039962176978588
step  400 0.3055257757008076
step  500 0.30677886989712716
step  600 0.3065928694357475
step  700 0.3067541199709688
step  800 0.30561958950012924
step  900 0.30536794135967893
step  1000 0.30571483458578586
step  1100 0.30464975718747483
step  1200 0.30406303743521373
step  1300 0.3040481885121419
step  1400 0.30420012292053017
step  1500 0.30411581149697303
step  1600 0.3037383827660233
step  1700 0.30375009379842705
step  1800 0.30375165893799727
step  1900 0.30365023938448804
val Loss: 0.3035 
Epoch 10/25
step  100 0.0025246123276883737
step  200 0.0027015869604656473
step  300 0.0027541143210449565
step  400 0.002742187510011718
step  500 0.0027101750895380974
step  600 0.00264622337766923
step  700 0.0026221710130006873
step  800 0.0026172107011370824
step  900 0.0026445382185435544
step  1000 0.0026507460877182895
step  1100 0.0026293356243034145
step  1200 0.0026372418719984125
step  1300 0.002638983508401837
step  1400 0.0026509661063235917
step  1500 0.0026598638475018865
step  1600 0.002645827158812608
step  1700 0.0026456060859046
step  1800 0.0026435778650274085
step  1900 0.002644997439776106
step  2000 0.00263569172390271
step  2100 0.002627873159945011
step  2200 0.0026296650027242403
step  2300 0.002625131843935536
step  2400 0.002632325858285185
step  2500 0.002639799642143771
step  2600 0.0026425454418998783
step  2700 0.002647743353370094
step  2800 0.002652082084844421
step  100 0.28233898043632505
step  200 0.2816426857560873
step  300 0.2793073876202106
step  400 0.28072188183665275
step  500 0.28052909326553344
step  600 0.28054493290682636
step  700 0.2799745609504836
step  800 0.2804920938424766
step  900 0.2810283632410897
step  1000 0.28110891819000244
step  1100 0.28126967557451943
step  1200 0.28077282770226397
step  1300 0.280822266798753
step  1400 0.2810814724756139
step  1500 0.2812773730754852
step  1600 0.28164706704206766
step  1700 0.2815877234497491
step  1800 0.2813899919307894
step  1900 0.28146935618237445
val Loss: 0.2814 
Epoch 11/25
